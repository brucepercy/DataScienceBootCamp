{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOxbEZ6i7HjqdVeqqH1yl1d"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GbxCgw6iv033","executionInfo":{"status":"ok","timestamp":1697078729845,"user_tz":240,"elapsed":171,"user":{"displayName":"Bruce Johnson","userId":"00953885078033609605"}},"outputId":"2577f6e7-6e76-4f85-a9a4-1709b84e867c"},"outputs":[{"output_type":"stream","name":"stdout","text":["     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n","0                  5.1               3.5                1.4               0.2\n","1                  4.9               3.0                1.4               0.2\n","2                  4.7               3.2                1.3               0.2\n","3                  4.6               3.1                1.5               0.2\n","4                  5.0               3.6                1.4               0.2\n","..                 ...               ...                ...               ...\n","145                6.7               3.0                5.2               2.3\n","146                6.3               2.5                5.0               1.9\n","147                6.5               3.0                5.2               2.0\n","148                6.2               3.4                5.4               2.3\n","149                5.9               3.0                5.1               1.8\n","\n","[150 rows x 4 columns]\n"]},{"output_type":"execute_result","data":{"text/plain":["sepal length (cm)    5.843333\n","sepal width (cm)     3.057333\n","petal length (cm)    3.758000\n","petal width (cm)     1.199333\n","dtype: float64"]},"metadata":{},"execution_count":12}],"source":["# # Import pandas and load iris dataset\n","# import pandas as pd\n","# from sklearn.datasets import load_iris\n","# data = load_iris()\n","\n","# # Convert the data to a pandas DataFrame\n","# df = pd.DataFrame(data['data'], columns = data['feature_names'])\n","# print(df)\n","\n","# df.mean()"]},{"cell_type":"code","source":["# # Add the target variable to the DataFrame\n","# df[‘target’] = data[‘target’] print(df)\n","\n","# # Split the DataFrame into training and testing sets\n","# from sklearn.model_selection import train_test_split X_train, X_test, y_train, y_test = train_test_split(df.drop(‘target’, axis=1), df[‘target’], test_size=0.2, random_state=42) print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n","\n","# # Import XGBClassifier and create an instance of it\n","# from xgboost import XGBClassifier clf = XGBClassifier() print(clf)\n","\n","# # Fit the XGBClassifier on the training set\n","# clf.fit(X_train, y_train)\n","\n","# # Predict the class labels of the testing set\n","# y_pred = clf.predict(X_test) print(y_pred)\n","\n","# # Evaluate the performance of the model\n","# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report print(‘Accuracy:’, accuracy_score(y_test, y_pred)) print(‘Confusion matrix:\\n’, confusion_matrix(y_test, y_pred)) print(‘Classification report:\\n’, classification_report(y_test, y_pred))"],"metadata":{"id":"-1EsU716zO7Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import pandas as pd\n","# from sklearn.model_selection import train_test_split\n","# from xgboost import XGBClassifier\n","# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# # Assuming 'data' is your original dataset and 'target' is the target variable\n","# # Create a DataFrame 'df' from your original data\n","# df = pd.DataFrame(data)\n","\n","# # Add the target variable to the DataFrame\n","# df['target'] = data['target']\n","\n","# # Split the DataFrame into training and testing sets\n","# X = df.drop('target', axis=1)  # Features\n","# y = df['target']  # Target variable\n","\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# # Import XGBClassifier and create an instance of it\n","# clf = XGBClassifier()\n","\n","# # Fit the XGBClassifier on the training set\n","# clf.fit(X_train, y_train)\n","\n","# # Predict the class labels of the testing set\n","# y_pred = clf.predict(X_test)\n","\n","# # Evaluate the performance of the model\n","# print('Accuracy:', accuracy_score(y_test, y_pred))\n","# print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n","# print('Classification report:\\n', classification_report(y_test, y_pred))\n"],"metadata":{"id":"jJpzDCdwzPBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from xgboost import XGBClassifier\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","from sklearn.datasets import load_iris\n","\n","# Load the Iris dataset\n","iris = load_iris()\n","data = pd.DataFrame(iris.data, columns=iris.feature_names)\n","data['target'] = iris.target\n","\n","# Split the DataFrame into features (X) and target (y)\n","X = data.drop('target', axis=1)  # Features\n","y = data['target']  # Target variable\n","\n","# Split the data into training and testing sets (80% train, 20% test)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Import XGBClassifier and create an instance of it\n","clf = XGBClassifier()\n","\n","# Fit the XGBClassifier on the training set\n","clf.fit(X_train, y_train)\n","\n","# Predict the class labels of the testing set\n","y_pred = clf.predict(X_test)\n","\n","# Evaluate the performance of the model\n","print('Accuracy:', accuracy_score(y_test, y_pred))\n","print('Confusion matrix:\\n', confusion_matrix(y_test, y_pred))\n","print('Classification report:\\n', classification_report(y_test, y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akizPjSI3sPe","executionInfo":{"status":"ok","timestamp":1697080415619,"user_tz":240,"elapsed":197,"user":{"displayName":"Bruce Johnson","userId":"00953885078033609605"}},"outputId":"2eeaed72-ac0e-4f8f-854c-6f6a98adbc3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 1.0\n","Confusion matrix:\n"," [[10  0  0]\n"," [ 0  9  0]\n"," [ 0  0 11]]\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        10\n","           1       1.00      1.00      1.00         9\n","           2       1.00      1.00      1.00        11\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n"]}]}]}