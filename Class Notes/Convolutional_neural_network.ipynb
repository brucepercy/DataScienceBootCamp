{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1l7QgmJ2HvvlMJjxiofc038D5f5GrguO0","timestamp":1697836926841}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"3DR-eO17geWu"},"source":["# Convolutional Neural Network"]},{"cell_type":"markdown","metadata":{"id":"EMefrVPCg-60"},"source":["### Importing the libraries"]},{"cell_type":"code","metadata":{"id":"sCV30xyVhFbE"},"source":["import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FIleuCAjoFD8","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1697836818787,"user_tz":240,"elapsed":7,"user":{"displayName":"Bruce Johnson","userId":"00953885078033609605"}},"outputId":"617304e6-2ead-456a-a4ca-e80665f9c02c"},"source":["tf.__version__"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.13.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUbCPjdvcjDT","executionInfo":{"status":"ok","timestamp":1697836847874,"user_tz":240,"elapsed":29091,"user":{"displayName":"Bruce Johnson","userId":"00953885078033609605"}},"outputId":"5503f1e0-9230-4045-e35d-5c4136ed961a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","metadata":{"id":"oxQxCBWyoGPE"},"source":["## Part 1 - Data Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"MvE-heJNo3GG"},"source":["### Preprocessing the Training set"]},{"cell_type":"code","metadata":{"id":"0koUcJMJpEBD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697836874509,"user_tz":240,"elapsed":26637,"user":{"displayName":"Bruce Johnson","userId":"00953885078033609605"}},"outputId":"acb839c2-7f16-48c8-fd87-ea80de273ad6"},"source":["train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                   shear_range = 0.2,\n","                                   zoom_range = 0.2,\n","                                   horizontal_flip = True)\n","training_set = train_datagen.flow_from_directory('/content/gdrive/MyDrive/Takeo/cayote_wolf/dataset/training_set',\n","                                                 target_size = (64, 64),\n","                                                 batch_size = 32,\n","                                                 class_mode = 'binary')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 8000 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"mrCMmGw9pHys"},"source":["### Preprocessing the Test set"]},{"cell_type":"code","metadata":{"id":"SH4WzfOhpKc3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697836880633,"user_tz":240,"elapsed":6126,"user":{"displayName":"Bruce Johnson","userId":"00953885078033609605"}},"outputId":"c347fa8d-20a1-469c-f01b-62a1035eedfe"},"source":["test_datagen = ImageDataGenerator(rescale = 1./255)\n","test_set = test_datagen.flow_from_directory('/content/gdrive/MyDrive/Takeo/cvvdataset/dataset/test_set',\n","                                            target_size = (64, 64),\n","                                            batch_size = 32,\n","                                            class_mode = 'binary')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 images belonging to 2 classes.\n"]}]},{"cell_type":"markdown","metadata":{"id":"af8O4l90gk7B"},"source":["## Part 2 - Building the CNN"]},{"cell_type":"markdown","metadata":{"id":"ces1gXY2lmoX"},"source":["### Initialising the CNN"]},{"cell_type":"code","metadata":{"id":"SAUt4UMPlhLS"},"source":["cnn = tf.keras.models.Sequential()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u5YJj_XMl5LF"},"source":["### Step 1 - Convolution"]},{"cell_type":"code","metadata":{"id":"XPzPrMckl-hV"},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n","# meaning of 64,64,3\n","# 64, 64 is pixels and 3 is the color , RGB"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tf87FpvxmNOJ"},"source":["### Step 2 - Pooling"]},{"cell_type":"code","metadata":{"id":"ncpqPl69mOac"},"source":["cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xaTOgD8rm4mU"},"source":["### Adding a second convolutional layer"]},{"cell_type":"code","metadata":{"id":"i_-FZjn_m8gk"},"source":["cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n","cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tmiEuvTunKfk"},"source":["### Step 3 - Flattening"]},{"cell_type":"code","metadata":{"id":"6AZeOGCvnNZn"},"source":["cnn.add(tf.keras.layers.Flatten())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dAoSECOm203v"},"source":["### Step 4 - Full Connection"]},{"cell_type":"code","metadata":{"id":"8GtmUlLd26Nq"},"source":["cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTldFvbX28Na"},"source":["### Step 5 - Output Layer"]},{"cell_type":"code","metadata":{"id":"1p_Zj1Mc3Ko_"},"source":["cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D6XkI90snSDl"},"source":["## Part 3 - Training the CNN"]},{"cell_type":"markdown","metadata":{"id":"vfrFQACEnc6i"},"source":["### Compiling the CNN"]},{"cell_type":"code","metadata":{"id":"NALksrNQpUlJ"},"source":["cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ehS-v3MIpX2h"},"source":["### Training the CNN on the Training set and evaluating it on the Test set"]},{"cell_type":"code","metadata":{"id":"XUj1W4PJptta"},"source":["cnn.fit(x = training_set, validation_data = test_set, epochs = 5)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3PZasO0006Z"},"source":["## Part 4 - Making a single prediction"]},{"cell_type":"code","metadata":{"id":"gsSiWEJY1BPB"},"source":["import numpy as np\n","from keras.preprocessing import image\n","test_image = image.load_img('/content/gdrive/MyDrive/Takeo/cvvdataset/dataset/single_prediction/cat_or_dog_1.jpg', target_size = (64, 64))\n","test_image = image.img_to_array(test_image)\n","test_image = np.expand_dims(test_image, axis = 0)\n","result = cnn.predict(test_image)\n","training_set.class_indices\n","if result[0][0] == 1:\n","  prediction = 'dog'\n","else:\n","  prediction = 'cat'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ED9KB3I54c1i"},"source":["print(prediction)"],"execution_count":null,"outputs":[]}]}